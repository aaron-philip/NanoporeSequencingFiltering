{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4792a70f",
   "metadata": {},
   "source": [
    "# Creating The Dataset\n",
    "\n",
    "We use all of the filtration and dataprocessing tools/code in filters.ipynb and dataprocessing.ipynb to actually generate a balanced dataset upon which to train our neural network. Our database is a single .h5 file called \"NanoporeFiltered.h5\". Inside it:\n",
    "- the segments of data are stored under the dataset \"NoisySignals\"\n",
    "- the low pass timestepped filter optimal parameters are stored under the dataset \"LowPass\"\n",
    "- the high pass timestepped filter optimal parameters are stored under the dataset \"HighPass\"\n",
    "- the band pass timestepped filter optimal parameters are stored under the dataset \"BandPass\"\n",
    "- the Butterworth low pass filter optimal parameters are stored under the dataset \"ButterworthLowPass\"\n",
    "\n",
    "By using our object-oriented code, we can keep appending to our dataset with a variety of genomic data from various sources. \n",
    "\n",
    "## Modules/Libraries\n",
    "All the original code used was already written in filters.ipynb and dataprocessing.ipynb. We simply use those notebooks and all their dependencies to keep building our database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100bf4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from filters.ipynb\n",
      "importing Jupyter notebook from dataprocessing.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Use filtration code developed in filters.ipynb and data processing tools in dataprocessing.ipynb to build dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "import math\n",
    "from typing import Optional\n",
    "import os\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "import import_ipynb\n",
    "from filters import Filters, TimesteppedFilters, ButterworthFilters\n",
    "from dataprocessing import genData, dataTreatment, writeH5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed89d13",
   "metadata": {},
   "source": [
    "## Paths\n",
    "The user provides the paths to DeepSimulator, the sequence of interest, the fasta file containing the sequence, and the database file to build the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9157ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DEEPSIM = '/Users/aaronphilip/ScienceFair/projects/NanoporeSequencingFiltering/DeepSimulator'\n",
    "SEQUENCE = 'artificial_human_chr22'\n",
    "PATH_TO_FASTA = os.path.join(PATH_TO_DEEPSIM, 'example/%s.fasta' % SEQUENCE)\n",
    "PATH_TO_H5 = '/Users/aaronphilip/ScienceFair/projects/NanoporeSequencingFiltering/database'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990ab44",
   "metadata": {},
   "source": [
    "## Data Processing and H5 Writing\n",
    "We recommend not using the 'Run All' command. This may result in database overwriting. Instead, after a group of data has been processed, change the H5NAME in that cell to some other name( we used 'test' ) to avoid accidentally running all cells and rewriting the database. In the cells below, we outline exactly how the user can append to their database using samples of various noise. Note that the genData object doesn't need to be created everytime, but can be used with mutliple .noisyRead() run consecutively to save some computation time. However, we initially built in 500 datapoint increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333fb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 segments of data with default noisy on Human Chr. 22\n",
    "H5NAME = 'test'\n",
    "humanChr22 = genData(PATH_TO_DEEPSIM, SEQUENCE, PATH_TO_FASTA)\n",
    "truthRead = humanChr22.truthRead()\n",
    "noisyRead = humanChr22.noisyRead()\n",
    "\n",
    "treated = dataTreatment(noisyRead, truthRead, 500)\n",
    "noisyData, labels, errors = treated.optParams()\n",
    "h5obj = writeH5(PATH_TO_H5, noisyData, labels, H5NAME)\n",
    "h5obj.initH5()\n",
    "h5obj.appendH5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a703c08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset: 37.0 , Range: 1368.36 , Digitisation: 8192.0\n",
      "Offset: 37.0 , Range: 1368.36 , Digitisation: 8192.0\n"
     ]
    }
   ],
   "source": [
    "# 500 segments of data from Human Chr. 22 with 90.3% typical accuracy w/o filtration\n",
    "H5NAME = 'test'\n",
    "humanChr22 = genData(PATH_TO_DEEPSIM, SEQUENCE, PATH_TO_FASTA)\n",
    "truthRead = humanChr22.truthRead()\n",
    "noisyRead = humanChr22.noisyRead(e=1.5, f=950, s=0)\n",
    "\n",
    "treated = dataTreatment(noisyRead, truthRead, 500)\n",
    "noisyData, labels, errors = treated.optParams()\n",
    "h5obj = writeH5(PATH_TO_H5, noisyData, labels, H5NAME)\n",
    "h5obj.appendH5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85adf225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset: 37.0 , Range: 1368.36 , Digitisation: 8192.0\n",
      "Offset: 37.0 , Range: 1368.36 , Digitisation: 8192.0\n"
     ]
    }
   ],
   "source": [
    "# 500 segments of data from Human Chr. 22 with 90.9% typical accuracy w/o filtration\n",
    "H5NAME = 'NanoporeFiltered'\n",
    "humanChr22 = genData(PATH_TO_DEEPSIM, SEQUENCE, PATH_TO_FASTA)\n",
    "truthRead = humanChr22.truthRead()\n",
    "noisyRead = humanChr22.noisyRead(e=0, f=950, s=2)\n",
    "\n",
    "treated = dataTreatment(noisyRead, truthRead, 500)\n",
    "noisyData, labels, errors = treated.optParams()\n",
    "h5obj = writeH5(PATH_TO_H5, noisyData, labels, H5NAME)\n",
    "h5obj.appendH5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84955eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 segments of data from Human Chr. 22 with 91% typical accuracy w/o filtration\n",
    "H5NAME = 'NanoporeFiltered'\n",
    "noisyRead = humanChr22.noisyRead(e=0, f=850, s=0)\n",
    "\n",
    "treated = dataTreatment(noisyRead, truthRead, 500)\n",
    "noisyData, labels, errors = treated.optParams()\n",
    "h5obj = writeH5(PATH_TO_H5, noisyData, labels, H5NAME)\n",
    "h5obj.appendH5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05cd8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 segments of data from Human Chr. 22 with 94% typical accuracy w/o filtration\n",
    "#not run yet\n",
    "H5NAME = 'NanoporeFiltered'\n",
    "noisyRead = humanChr22.noisyRead(e=0.5, f=950, s=0)\n",
    "\n",
    "treated = dataTreatment(noisyRead, truthRead, 500)\n",
    "noisyData, labels, errors = treated.optParams()\n",
    "h5obj = writeH5(PATH_TO_H5, noisyData, labels, H5NAME)\n",
    "h5obj.appendH5()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
