{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4792a70f",
   "metadata": {},
   "source": [
    "# Creating The Dataset\n",
    "\n",
    "We use all of the filtration and dataprocessing tools/code in filters.ipynb and dataprocessing.ipynb to actually generate a balanced dataset upon which to train our neural network. Our database is a single .h5 file called \"NanoporeFiltered.h5\". Inside it:\n",
    "- the segments of data are stored under the dataset \"NoisySignals\"\n",
    "- the low pass timestepped filter optimal parameters are stored under the dataset \"LowPass\"\n",
    "- the high pass timestepped filter optimal parameters are stored under the dataset \"HighPass\"\n",
    "- the band pass timestepped filter optimal parameters are stored under the dataset \"BandPass\"\n",
    "- the Butterworth low pass filter optimal parameters are stored under the dataset \"ButterworthLowPass\"\n",
    "\n",
    "By using our object-oriented code, we can keep appending to our dataset with a variety of genomic data from various sources. \n",
    "\n",
    "## Modules/Libraries\n",
    "All the original code used was already written in filters.ipynb and dataprocessing.ipynb. We simply use those notebooks and all their dependencies to keep building our database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100bf4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from filters.ipynb\n",
      "importing Jupyter notebook from dataprocessing.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Use filtration code developed in filters.ipynb and data processing tools in dataprocessing.ipynb to build dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "import math\n",
    "from typing import Optional\n",
    "import os\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "import import_ipynb\n",
    "from filters import Filters, TimesteppedFilters, ButterworthFilters\n",
    "from dataprocessing import genData, dataTreatment, writeH5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed89d13",
   "metadata": {},
   "source": [
    "## Paths\n",
    "The user provides the paths to DeepSimulator, the sequence of interest, the fasta file containing the sequence, and the database file to build the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9157ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DEEPSIM = '/Users/aaronphilip/ScienceFair/projects/NanoporeSequencingFiltering/DeepSimulator'\n",
    "SEQUENCE = 'artificial_human_chr22'\n",
    "PATH_TO_FASTA = os.path.join(PATH_TO_DEEPSIM, 'example/%s.fasta' % SEQUENCE)\n",
    "PATH_TO_H5 = '/Users/aaronphilip/ScienceFair/projects/NanoporeSequencingFiltering/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f80a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset: 37.0 , Range: 1368.36 , Digitisation: 8192.0\n",
      "Offset: 37.0 , Range: 1368.36 , Digitisation: 8192.0\n"
     ]
    }
   ],
   "source": [
    "humanChr22 = genData(PATH_TO_DEEPSIM, SEQUENCE, PATH_TO_FASTA)\n",
    "truthRead = humanChr22.truthRead()\n",
    "noisyRead = humanChr22.noisyRead()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990ab44",
   "metadata": {},
   "source": [
    "## Data Processing and H5 Writing\n",
    "It should be noted that the user should **never** use \"Run All\" in this script. This will overwrite the database. Instead, work cell-by-cell to generate results for new data to append to the database. All cells besides the below can be run multiple times. Only run the .initH5() command when creating the database file for the first time or starting over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333fb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "treated = dataTreatment(noisyRead, truthRead, 500)\n",
    "noisyData, labels, errors = treated.optParams()\n",
    "h5obj = writeH5(PATH_TO_H5, noisyData, labels)\n",
    "h5obj.initH5()\n",
    "h5obj.appendH5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703c08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
